"""
BioKANãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸè»¢ç§»å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
MNISTã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’Fashion-MNISTã«è»¢ç§»ã™ã‚‹ä¾‹
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import os
import time
from contextlib import nullcontext
from sklearn.metrics import accuracy_score, confusion_matrix

# BioKANãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from biokan.core.biokan_model import create_biokan_classifier, NeuropharmacologicalBioKAN
    from biokan_training import EnhancedBioKANModel
    from biokan_transfer_learning import TransferBioKANModel
    BIOKAN_AVAILABLE = True
except ImportError:
    print("BioKANãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªMLPãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    BIOKAN_AVAILABLE = False

# CUDAé–¢é€£ã®è¨­å®š
os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # æœ€åˆã®GPUã‚’ä½¿ç”¨
torch.backends.cudnn.benchmark = True     # CUDNNã®è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒŠãƒ¼ã‚’æœ‰åŠ¹åŒ–
torch.backends.cudnn.deterministic = True # å†ç¾æ€§ã®ãŸã‚

# ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’å›ºå®š
SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

# GPUåˆ©ç”¨å¯èƒ½æ€§ã®ç¢ºèª
if not torch.cuda.is_available():
    print("è­¦å‘Š: GPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    device = torch.device("cpu")
else:
    device = torch.device("cuda")
    print(f"ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
    print(f"åˆ©ç”¨å¯èƒ½ãªGPUãƒ¡ãƒ¢ãƒª: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# Fashion-MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ©ãƒ™ãƒ«
fashion_labels = {
    0: 'Tã‚·ãƒ£ãƒ„/ãƒˆãƒƒãƒ—',
    1: 'ã‚ºãƒœãƒ³',
    2: 'ãƒ—ãƒ«ã‚ªãƒ¼ãƒãƒ¼',
    3: 'ãƒ‰ãƒ¬ã‚¹',
    4: 'ã‚³ãƒ¼ãƒˆ',
    5: 'ã‚µãƒ³ãƒ€ãƒ«',
    6: 'ã‚·ãƒ£ãƒ„',
    7: 'ã‚¹ãƒ‹ãƒ¼ã‚«ãƒ¼',
    8: 'ãƒãƒƒã‚°',
    9: 'ã‚¢ãƒ³ã‚¯ãƒ«ãƒ–ãƒ¼ãƒ„'
}

# ã‚·ãƒ³ãƒ—ãƒ«ãªMLPã‚¯ãƒ©ã‚¹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä½¿ç”¨ï¼‰
class SimpleMLP(nn.Module):
    def __init__(self, in_features, hidden_dim, num_classes):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(in_features, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, num_classes)
        )
    
    def forward(self, x):
        return self.model(x)

# è»¢ç§»å­¦ç¿’ç”¨ã®TransferMLPã‚¯ãƒ©ã‚¹
class TransferMLP(nn.Module):
    def __init__(self, pretrained_model, num_classes=10, freeze_base=True):
        super().__init__()
        # äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
        self.base_model = pretrained_model
        
        # æœ€çµ‚å±¤ã‚’é™¤ãå…¨ã¦ã®å±¤ã‚’ãƒ•ãƒªãƒ¼ã‚ºã™ã‚‹ã‹ã©ã†ã‹
        if freeze_base:
            for param in self.base_model.parameters():
                param.requires_grad = False
        
        # MLPã®å ´åˆã€æœ€çµ‚å±¤ã‚’æŠ½å‡ºã—ã¦ç½®ãæ›ãˆ
        if isinstance(pretrained_model, SimpleMLP):
            # SimpleMLPç”¨ã®å‡¦ç†
            # ãƒ¢ãƒ‡ãƒ«å†…ã®æœ€çµ‚å±¤ã‚’æ–°ã—ã„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¯ãƒ©ã‚¹æ•°ç”¨ã«ç½®ãæ›ãˆ
            self.base_model.model[-1] = nn.Linear(self.base_model.model[-3].out_features, num_classes)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å‡¦ç†ï¼ˆBioKANãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰
            # BioKANãƒ¢ãƒ‡ãƒ«ã¯é€šå¸¸classifierã¨ã„ã†å±æ€§ã‚’æŒã¤ãŸã‚
            try:
                in_features = self.base_model.classifier.in_features
                self.base_model.classifier = nn.Linear(in_features, num_classes)
            except AttributeError:
                print("æ³¨æ„: ãƒ¢ãƒ‡ãƒ«ã«.classifierå±æ€§ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä»£æ›¿æ‰‹æ®µã§å¯¾å¿œã—ã¾ã™ã€‚")
                # ä»£æ›¿æ‰‹æ®µï¼šãƒ¢ãƒ‡ãƒ«ã®æœ€å¾Œã®å±¤ã‚’ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã§æ¢ã—ã¦ç½®ãæ›ãˆ
                last_layer = None
                for name, module in self.base_model.named_modules():
                    if isinstance(module, nn.Linear):
                        last_layer = module
                
                if last_layer is not None:
                    in_features = last_layer.in_features
                    setattr(self.base_model, name, nn.Linear(in_features, num_classes))
    
    def forward(self, x):
        return self.base_model(x)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰
def load_datasets(batch_size=64, dataset_type='fashion_mnist'):
    print(f"\n{dataset_type}ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...")
    
    # å¤‰æ›ã®å®šç¾©
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))  # æ¨™æº–çš„ãªæ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    ])
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é¸æŠ
    if dataset_type.lower() == 'fashion_mnist':
        train_dataset = torchvision.datasets.FashionMNIST(
            root='./data', train=True, transform=transform, download=True
        )
        test_dataset = torchvision.datasets.FashionMNIST(
            root='./data', train=False, transform=transform, download=True
        )
    elif dataset_type.lower() == 'cifar10':
        # CIFAR-10ç”¨ã®å¤‰æ›ï¼ˆã‚«ãƒ©ãƒ¼ç”»åƒã€ã‚µã‚¤ã‚ºãŒç•°ãªã‚‹ï¼‰
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
            transforms.Grayscale(),  # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›ï¼ˆMNISTã¨åˆã‚ã›ã‚‹ï¼‰
            transforms.Resize((28, 28))  # MNISTã¨åŒã˜ã‚µã‚¤ã‚ºã«å¤‰æ›´
        ])
        train_dataset = torchvision.datasets.CIFAR10(
            root='./data', train=True, transform=transform, download=True
        )
        test_dataset = torchvision.datasets.CIFAR10(
            root='./data', train=False, transform=transform, download=True
        )
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Fashion-MNIST
        print(f"è­¦å‘Š: æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒ— '{dataset_type}'ã€‚Fashion-MNISTã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        train_dataset = torchvision.datasets.FashionMNIST(
            root='./data', train=True, transform=transform, download=True
        )
        test_dataset = torchvision.datasets.FashionMNIST(
            root='./data', train=False, transform=transform, download=True
        )
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ
    train_loader = torch.utils.data.DataLoader(
        dataset=train_dataset, batch_size=batch_size, shuffle=True
    )
    
    test_loader = torch.utils.data.DataLoader(
        dataset=test_dataset, batch_size=batch_size, shuffle=False
    )
    
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(train_dataset):,}ä»¶")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(test_dataset):,}ä»¶")
    
    return train_loader, test_loader

# äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
def load_pretrained_model(model_path, model_type='biokan'):
    print(f"\näº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {model_path}")
    
    # MNISTã®å…¥åŠ›ã‚µã‚¤ã‚º: 28x28 = 784
    in_features = 28 * 28
    
    if model_type.lower() == 'biokan' and BIOKAN_AVAILABLE:
        try:
            # BioKANãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            model = create_biokan_classifier(
                in_features=in_features,
                hidden_dim=128,
                num_classes=10,  # MNIST: 10ã‚¯ãƒ©ã‚¹ (0-9)
                num_blocks=3,
                attention_type='standard',
                dropout=0.2,
                neuromodulation=True
            )
            # ä¿å­˜ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
            model.load_state_dict(torch.load(model_path, map_location=device))
            print("BioKANãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
            return model
        except Exception as e:
            print(f"BioKANãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
            print("æ¨™æº–çš„ãªMLPãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯...")
    
    # BioKANãŒä½¿ç”¨ã§ããªã„ã‹ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã‚·ãƒ³ãƒ—ãƒ«ãªMLPã‚’ä½¿ç”¨
    model = SimpleMLP(in_features, 128, 10)
    try:
        # ä¿å­˜ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
        model.load_state_dict(torch.load(model_path, map_location=device))
        print("MLPãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
        print("ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
    
    return model

# è»¢ç§»å­¦ç¿’ã®å®Ÿè¡Œ
def train_transfer_model(model, train_loader, test_loader, epochs=10, lr=0.0001, weight_decay=1e-5):
    print("\nè»¢ç§»å­¦ç¿’ã‚’é–‹å§‹...")
    
    # æå¤±é–¢æ•°ã¨æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®šç¾©
    criterion = nn.CrossEntropyLoss()
    
    # å­¦ç¿’ç‡ã‚’å°ã•ãè¨­å®šï¼ˆå¾®èª¿æ•´ã®ãŸã‚ï¼‰
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    
    # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=2, verbose=True
    )
    
    # å­¦ç¿’å±¥æ­´ã‚’ä¿å­˜
    history = {
        'train_loss': [],
        'train_acc': [],
        'test_loss': [],
        'test_acc': [],
        'best_test_acc': 0.0,
        'best_epoch': 0
    }
    
    # é–‹å§‹æ™‚é–“
    start_time = time.time()
    
    # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—
    for epoch in range(epochs):
        model.train()  # å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰
        epoch_loss = 0.0
        epoch_correct = 0
        epoch_total = 0
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰ãƒãƒƒãƒã‚’å–å¾—
        for batch_idx, (images, labels) in enumerate(tqdm(train_loader, desc=f"ã‚¨ãƒãƒƒã‚¯ {epoch+1}/{epochs}")):
            # ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«è»¢é€
            images = images.reshape(images.shape[0], -1).to(device)  # [batch, 784]
            labels = labels.to(device)
            
            # å‹¾é…ã‚’ã‚¼ãƒ­ã«åˆæœŸåŒ–
            optimizer.zero_grad()
            
            # é †ä¼æ’­
            outputs = model(images)
            
            # æå¤±ã‚’è¨ˆç®—
            loss = criterion(outputs, labels)
            
            # é€†ä¼æ’­
            loss.backward()
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°
            optimizer.step()
            
            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            epoch_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            epoch_total += labels.size(0)
            epoch_correct += (predicted == labels).sum().item()
            
            # GPUãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if batch_idx % 50 == 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        # ã‚¨ãƒãƒƒã‚¯ã®å¹³å‡æå¤±ã¨ç²¾åº¦ã‚’è¨ˆç®—
        epoch_loss /= len(train_loader)
        epoch_acc = epoch_correct / epoch_total
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
        test_loss, test_acc = evaluate_model(model, test_loader, criterion)
        
        # å­¦ç¿’ç‡ã‚’èª¿æ•´
        scheduler.step(test_loss)
        
        # å­¦ç¿’å±¥æ­´ã‚’æ›´æ–°
        history['train_loss'].append(epoch_loss)
        history['train_acc'].append(epoch_acc)
        history['test_loss'].append(test_loss)
        history['test_acc'].append(test_acc)
        
        # æœ€é«˜ç²¾åº¦ã‚’ä¿å­˜
        if test_acc > history['best_test_acc']:
            history['best_test_acc'] = test_acc
            history['best_epoch'] = epoch + 1
            
            # æœ€é«˜ç²¾åº¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            torch.save(model.state_dict(), 'best_transfer_model.pth')
            print(f"ğŸ”” æ–°ã—ã„æœ€é«˜ç²¾åº¦ã‚’é”æˆï¼ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        
        # ã‚¨ãƒãƒƒã‚¯ã®çµæœã‚’è¡¨ç¤º
        print(f"ã‚¨ãƒãƒƒã‚¯ {epoch+1}/{epochs} - "
              f"è¨“ç·´æå¤±: {epoch_loss:.4f}, è¨“ç·´ç²¾åº¦: {epoch_acc:.4f}, "
              f"ãƒ†ã‚¹ãƒˆæå¤±: {test_loss:.4f}, ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc:.4f}")
    
    # çµŒéæ™‚é–“
    elapsed_time = time.time() - start_time
    print(f"\nè»¢ç§»å­¦ç¿’å®Œäº†ï¼ç·æ™‚é–“: {elapsed_time:.1f}ç§’")
    print(f"æœ€é«˜ãƒ†ã‚¹ãƒˆç²¾åº¦: {history['best_test_acc']:.4f} (ã‚¨ãƒãƒƒã‚¯ {history['best_epoch']})")
    
    # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    torch.save(model.state_dict(), 'final_transfer_model.pth')
    print("æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: final_transfer_model.pth")
    
    return model, history

# ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
def evaluate_model(model, test_loader, criterion=None):
    model.eval()  # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰
    
    if criterion is None:
        criterion = nn.CrossEntropyLoss()
    
    test_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.reshape(images.shape[0], -1).to(device)
            labels = labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            test_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    test_loss /= len(test_loader)
    test_acc = correct / total
    
    return test_loss, test_acc

# å­¦ç¿’å±¥æ­´ã®å¯è¦–åŒ–
def plot_training_history(history):
    plt.figure(figsize=(12, 5))
    
    # æå¤±ã®ãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='è¨“ç·´æå¤±')
    plt.plot(history['test_loss'], label='ãƒ†ã‚¹ãƒˆæå¤±')
    plt.xlabel('ã‚¨ãƒãƒƒã‚¯')
    plt.ylabel('æå¤±')
    plt.title('è»¢ç§»å­¦ç¿’ - æå¤±ã®æ¨ç§»')
    plt.legend()
    plt.grid(alpha=0.3)
    
    # ç²¾åº¦ã®ãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(1, 2, 2)
    plt.plot(history['train_acc'], label='è¨“ç·´ç²¾åº¦')
    plt.plot(history['test_acc'], label='ãƒ†ã‚¹ãƒˆç²¾åº¦')
    plt.xlabel('ã‚¨ãƒãƒƒã‚¯')
    plt.ylabel('ç²¾åº¦')
    plt.title('è»¢ç§»å­¦ç¿’ - ç²¾åº¦ã®æ¨ç§»')
    plt.legend()
    plt.grid(alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('transfer_learning_history.png')
    print("å­¦ç¿’å±¥æ­´ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: transfer_learning_history.png")

# æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–
def plot_confusion_matrix(model, test_loader, class_names):
    model.eval()
    
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.reshape(images.shape[0], -1).to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            
            all_preds.append(predicted.cpu().numpy())
            all_labels.append(labels.numpy())
    
    # numpyé…åˆ—ã«å¤‰æ›
    all_preds = np.concatenate(all_preds)
    all_labels = np.concatenate(all_labels)
    
    # æ··åŒè¡Œåˆ—ã®è¨ˆç®—
    cm = confusion_matrix(all_labels, all_preds)
    
    # æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–
    plt.figure(figsize=(10, 8))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title("æ··åŒè¡Œåˆ—")
    plt.colorbar()
    tick_marks = np.arange(len(class_names))
    plt.xticks(tick_marks, class_names, rotation=45)
    plt.yticks(tick_marks, class_names)
    plt.xlabel("äºˆæ¸¬ãƒ©ãƒ™ãƒ«")
    plt.ylabel("å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«")
    
    # å„ã‚»ãƒ«ã®å€¤ã‚’è¡¨ç¤º
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, format(cm[i, j], 'd'),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    
    plt.tight_layout()
    plt.savefig('transfer_learning_confusion_matrix.png')
    print("æ··åŒè¡Œåˆ—ã‚’ä¿å­˜ã—ã¾ã—ãŸ: transfer_learning_confusion_matrix.png")
    
    # ã‚¯ãƒ©ã‚¹ã”ã¨ã®ç²¾åº¦
    class_accuracy = cm.diagonal() / cm.sum(axis=1)
    
    plt.figure(figsize=(12, 6))
    plt.bar(np.arange(len(class_names)), class_accuracy)
    plt.xlabel("ã‚¯ãƒ©ã‚¹")
    plt.ylabel("ç²¾åº¦")
    plt.title("ã‚¯ãƒ©ã‚¹ã”ã¨ã®ç²¾åº¦")
    plt.xticks(np.arange(len(class_names)), class_names, rotation=45)
    plt.ylim(0, 1)
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig('transfer_learning_class_accuracy.png')
    print("ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦ã‚’ä¿å­˜ã—ã¾ã—ãŸ: transfer_learning_class_accuracy.png")

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã¨äºˆæ¸¬çµæœã®å¯è¦–åŒ–
def visualize_predictions(model, test_loader, class_names, num_samples=10):
    model.eval()
    
    # ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—
    images, labels = next(iter(test_loader))
    images = images[:num_samples]
    labels = labels[:num_samples]
    
    # äºˆæ¸¬ã‚’å®Ÿè¡Œ
    with torch.no_grad():
        images_flat = images.reshape(images.shape[0], -1).to(device)
        outputs = model(images_flat)
        _, predicted = torch.max(outputs, 1)
        
        # äºˆæ¸¬ç¢ºç‡ã‚’å–å¾—
        probs = torch.nn.functional.softmax(outputs, dim=1)
    
    # ç”»åƒã¨äºˆæ¸¬çµæœã‚’è¡¨ç¤º
    fig, axes = plt.subplots(2, 5, figsize=(15, 6))
    axes = axes.ravel()
    
    for i in range(num_samples):
        # ç”»åƒã‚’è¡¨ç¤º
        axes[i].imshow(images[i].squeeze().numpy(), cmap='gray')
        
        # äºˆæ¸¬ãŒæ­£ã—ã„ã‹ã©ã†ã‹ã§è‰²åˆ†ã‘
        color = 'green' if predicted[i] == labels[i] else 'red'
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã«äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã¨ç¢ºç‡ã‚’è¡¨ç¤º
        pred_class = class_names[predicted[i].item()]
        true_class = class_names[labels[i].item()]
        confidence = probs[i, predicted[i]].item()
        
        axes[i].set_title(f"äºˆæ¸¬: {pred_class}\nå®Ÿéš›: {true_class}\nç¢ºä¿¡åº¦: {confidence:.2f}", 
                          color=color, fontsize=9)
        axes[i].axis('off')
    
    plt.tight_layout()
    plt.savefig('transfer_learning_predictions.png')
    print("äºˆæ¸¬çµæœã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: transfer_learning_predictions.png")

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if __name__ == "__main__":
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é¸æŠ
        target_dataset = 'fashion_mnist'  # 'fashion_mnist' ã¾ãŸã¯ 'cifar10'
        
        # ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰
        train_loader, test_loader = load_datasets(batch_size=128, dataset_type=target_dataset)
        
        # ã‚¯ãƒ©ã‚¹åã®ãƒãƒƒãƒ”ãƒ³ã‚°
        if target_dataset.lower() == 'fashion_mnist':
            class_names = [fashion_labels[i] for i in range(10)]
        elif target_dataset.lower() == 'cifar10':
            # CIFAR-10ã®ã‚¯ãƒ©ã‚¹å
            class_names = ['é£›è¡Œæ©Ÿ', 'è‡ªå‹•è»Š', 'é³¥', 'çŒ«', 'é¹¿', 'çŠ¬', 'ã‚«ã‚¨ãƒ«', 'é¦¬', 'èˆ¹', 'ãƒˆãƒ©ãƒƒã‚¯']
        else:
            class_names = [str(i) for i in range(10)]
        
        # äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
        model_path = 'best_biokan_mnist_model.pth'
        
        # äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
        if not os.path.exists(model_path):
            print(f"è­¦å‘Š: æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« '{model_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            print("ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            
            # ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
            in_features = 28 * 28
            if BIOKAN_AVAILABLE:
                try:
                    base_model = create_biokan_classifier(
                        in_features=in_features,
                        hidden_dim=128,
                        num_classes=10,
                        num_blocks=3,
                        attention_type='standard',
                        dropout=0.2,
                        neuromodulation=True
                    )
                except Exception as e:
                    print(f"BioKANãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    base_model = SimpleMLP(in_features, 128, 10)
            else:
                base_model = SimpleMLP(in_features, 128, 10)
        else:
            # äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
            base_model = load_pretrained_model(model_path)
        
        # è»¢ç§»å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
        transfer_model = TransferMLP(base_model, num_classes=10, freeze_base=False)
        transfer_model = transfer_model.to(device)
        print(f"è»¢ç§»å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’{device}ã«è»¢é€ã—ã¾ã—ãŸ")
        
        # è»¢ç§»å­¦ç¿’ã®å®Ÿè¡Œ
        trained_model, history = train_transfer_model(
            transfer_model,
            train_loader,
            test_loader,
            epochs=10,
            lr=0.0001,
            weight_decay=1e-5
        )
        
        # å­¦ç¿’å±¥æ­´ã®å¯è¦–åŒ–
        plot_training_history(history)
        
        # æ··åŒè¡Œåˆ—ã¨ç²¾åº¦ã®å¯è¦–åŒ–
        plot_confusion_matrix(trained_model, test_loader, class_names)
        
        # ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬ã®å¯è¦–åŒ–
        visualize_predictions(trained_model, test_loader, class_names)
        
        # æœ€çµ‚è©•ä¾¡
        _, final_acc = evaluate_model(trained_model, test_loader)
        print(f"\næœ€çµ‚ãƒ†ã‚¹ãƒˆç²¾åº¦: {final_acc:.4f}")
        
        print("\nè»¢ç§»å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ä»¥ä¸‹ã®ãƒ‘ã‚¹ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™:")
        print("- æœ€é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«: best_transfer_model.pth")
        print("- æœ€çµ‚ãƒ¢ãƒ‡ãƒ«: final_transfer_model.pth")
        
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        # GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã®è¡¨ç¤º
        if torch.cuda.is_available():
            print("\nGPUãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³:")
            print(f"å‰²ã‚Šå½“ã¦æ¸ˆã¿ãƒ¡ãƒ¢ãƒª: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")
            print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒª: {torch.cuda.memory_reserved() / 1024**2:.1f} MB")
            # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±ã‚’å‡ºåŠ›
            import traceback
            traceback.print_exc()
            torch.cuda.empty_cache()  # GPUãƒ¡ãƒ¢ãƒªã®è§£æ”¾
    
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if torch.cuda.is_available():
            torch.cuda.empty_cache() 