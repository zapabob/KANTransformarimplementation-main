"""
MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ãŸBioKANãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import os
import time
from contextlib import nullcontext
from sklearn.metrics import accuracy_score, confusion_matrix

# BioKANãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from biokan.core.biokan_model import create_biokan_classifier, NeuropharmacologicalBioKAN
    BioKAN_AVAILABLE = True
except ImportError:
    print("BioKANãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªMLPãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    BioKAN_AVAILABLE = False

# CUDAé–¢é€£ã®è¨­å®š
os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # æœ€åˆã®GPUã‚’ä½¿ç”¨
torch.backends.cudnn.benchmark = True     # CUDNNã®è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒŠãƒ¼ã‚’æœ‰åŠ¹åŒ–
torch.backends.cudnn.deterministic = True # å†ç¾æ€§ã®ãŸã‚

# ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’å›ºå®š
SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

# GPUåˆ©ç”¨å¯èƒ½æ€§ã®ç¢ºèª
if not torch.cuda.is_available():
    print("è­¦å‘Š: GPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    device = torch.device("cpu")
else:
    device = torch.device("cuda")
    print(f"ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
    print(f"åˆ©ç”¨å¯èƒ½ãªGPUãƒ¡ãƒ¢ãƒª: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
def load_mnist_data(batch_size=64):
    print("\nMNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...")
    
    # å¤‰æ›ã®å®šç¾©
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))  # MNISTã®å¹³å‡ã¨æ¨™æº–åå·®
    ])
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
    train_dataset = torchvision.datasets.MNIST(
        root='./data', 
        train=True, 
        transform=transform,
        download=True
    )
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
    test_dataset = torchvision.datasets.MNIST(
        root='./data', 
        train=False, 
        transform=transform,
        download=True
    )
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ
    train_loader = torch.utils.data.DataLoader(
        dataset=train_dataset,
        batch_size=batch_size,
        shuffle=True
    )
    
    test_loader = torch.utils.data.DataLoader(
        dataset=test_dataset,
        batch_size=batch_size,
        shuffle=False
    )
    
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(train_dataset):,}ä»¶")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(test_dataset):,}ä»¶")
    
    return train_loader, test_loader

# ã‚·ãƒ³ãƒ—ãƒ«ãªMLPã‚¯ãƒ©ã‚¹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä½¿ç”¨ï¼‰
class SimpleMLP(nn.Module):
    def __init__(self, in_features, hidden_dim, num_classes):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(in_features, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, num_classes)
        )
    
    def forward(self, x):
        return self.model(x)

# BioKANãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
def initialize_model():
    print("\nãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
    
    # MNISTã®å…¥åŠ›ã‚µã‚¤ã‚º: 28x28 = 784
    in_features = 28 * 28
    
    if BioKAN_AVAILABLE:
        try:
            # BioKANãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            model = create_biokan_classifier(
                in_features=in_features,
                hidden_dim=128,
                num_classes=10,  # MNIST: 10ã‚¯ãƒ©ã‚¹ (0-9)
                num_blocks=3,
                attention_type='standard',  # standardã§å˜ç´”åŒ–
                dropout=0.2,
                neuromodulation=True  # å­¦ç¿’æ™‚ã«ã¯ç¥çµŒèª¿ç¯€ã‚’æœ‰åŠ¹åŒ–
            )
            print("BioKANãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
            return model
        except Exception as e:
            print(f"BioKANãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            print("æ¨™æº–çš„ãªMLPãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯...")
    
    # BioKANãŒä½¿ç”¨ã§ããªã„å ´åˆã¯ã‚·ãƒ³ãƒ—ãƒ«ãªMLPã‚’ä½¿ç”¨
    print("ã‚·ãƒ³ãƒ—ãƒ«ãªMLPãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
    return SimpleMLP(in_features, 128, 10)

# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
def train_model(model, train_loader, test_loader, epochs=10, lr=0.001, weight_decay=1e-5):
    print("\nãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’é–‹å§‹...")
    
    # æå¤±é–¢æ•°ã¨æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®šç¾©
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    
    # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ï¼ˆå­¦ç¿’ç‡ã‚’å¾ã€…ã«æ¸›å°‘ã•ã›ã‚‹ï¼‰
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=2, verbose=True
    )
    
    # å­¦ç¿’å±¥æ­´ã‚’ä¿å­˜
    history = {
        'train_loss': [],
        'train_acc': [],
        'test_loss': [],
        'test_acc': [],
        'best_test_acc': 0.0,
        'best_epoch': 0
    }
    
    # é–‹å§‹æ™‚é–“
    start_time = time.time()
    
    # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—
    for epoch in range(epochs):
        model.train()  # å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰
        epoch_loss = 0.0
        epoch_correct = 0
        epoch_total = 0
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰ãƒãƒƒãƒã‚’å–å¾—
        for batch_idx, (images, labels) in enumerate(tqdm(train_loader, desc=f"ã‚¨ãƒãƒƒã‚¯ {epoch+1}/{epochs}")):
            # ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«è»¢é€
            images = images.reshape(images.shape[0], -1).to(device)  # [batch, 784]
            labels = labels.to(device)
            
            # å‹¾é…ã‚’ã‚¼ãƒ­ã«åˆæœŸåŒ–
            optimizer.zero_grad()
            
            # é †ä¼æ’­
            outputs = model(images)
            
            # æå¤±ã‚’è¨ˆç®—
            loss = criterion(outputs, labels)
            
            # é€†ä¼æ’­
            loss.backward()
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°
            optimizer.step()
            
            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            epoch_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            epoch_total += labels.size(0)
            epoch_correct += (predicted == labels).sum().item()
            
            # GPUãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if batch_idx % 50 == 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        # ã‚¨ãƒãƒƒã‚¯ã®å¹³å‡æå¤±ã¨ç²¾åº¦ã‚’è¨ˆç®—
        epoch_loss /= len(train_loader)
        epoch_acc = epoch_correct / epoch_total
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
        test_loss, test_acc = evaluate_model(model, test_loader, criterion)
        
        # å­¦ç¿’ç‡ã‚’èª¿æ•´
        scheduler.step(test_loss)
        
        # å­¦ç¿’å±¥æ­´ã‚’æ›´æ–°
        history['train_loss'].append(epoch_loss)
        history['train_acc'].append(epoch_acc)
        history['test_loss'].append(test_loss)
        history['test_acc'].append(test_acc)
        
        # æœ€é«˜ç²¾åº¦ã‚’ä¿å­˜
        if test_acc > history['best_test_acc']:
            history['best_test_acc'] = test_acc
            history['best_epoch'] = epoch + 1
            
            # æœ€é«˜ç²¾åº¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            torch.save(model.state_dict(), 'best_biokan_mnist_model.pth')
            print(f"ğŸ”” æ–°ã—ã„æœ€é«˜ç²¾åº¦ã‚’é”æˆï¼ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        
        # ã‚¨ãƒãƒƒã‚¯ã®çµæœã‚’è¡¨ç¤º
        print(f"ã‚¨ãƒãƒƒã‚¯ {epoch+1}/{epochs} - "
              f"è¨“ç·´æå¤±: {epoch_loss:.4f}, è¨“ç·´ç²¾åº¦: {epoch_acc:.4f}, "
              f"ãƒ†ã‚¹ãƒˆæå¤±: {test_loss:.4f}, ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc:.4f}")
    
    # çµŒéæ™‚é–“
    elapsed_time = time.time() - start_time
    print(f"\nå­¦ç¿’å®Œäº†ï¼ç·æ™‚é–“: {elapsed_time:.1f}ç§’")
    print(f"æœ€é«˜ãƒ†ã‚¹ãƒˆç²¾åº¦: {history['best_test_acc']:.4f} (ã‚¨ãƒãƒƒã‚¯ {history['best_epoch']})")
    
    # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    torch.save(model.state_dict(), 'final_biokan_mnist_model.pth')
    print("æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: final_biokan_mnist_model.pth")
    
    return model, history

# ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
def evaluate_model(model, test_loader, criterion=None):
    model.eval()  # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰
    
    if criterion is None:
        criterion = nn.CrossEntropyLoss()
    
    test_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.reshape(images.shape[0], -1).to(device)
            labels = labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            test_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    test_loss /= len(test_loader)
    test_acc = correct / total
    
    return test_loss, test_acc

# å­¦ç¿’å±¥æ­´ã®å¯è¦–åŒ–
def plot_training_history(history):
    plt.figure(figsize=(12, 5))
    
    # æå¤±ã®ãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='è¨“ç·´æå¤±')
    plt.plot(history['test_loss'], label='ãƒ†ã‚¹ãƒˆæå¤±')
    plt.xlabel('ã‚¨ãƒãƒƒã‚¯')
    plt.ylabel('æå¤±')
    plt.title('å­¦ç¿’æå¤±ã®æ¨ç§»')
    plt.legend()
    plt.grid(alpha=0.3)
    
    # ç²¾åº¦ã®ãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(1, 2, 2)
    plt.plot(history['train_acc'], label='è¨“ç·´ç²¾åº¦')
    plt.plot(history['test_acc'], label='ãƒ†ã‚¹ãƒˆç²¾åº¦')
    plt.xlabel('ã‚¨ãƒãƒƒã‚¯')
    plt.ylabel('ç²¾åº¦')
    plt.title('å­¦ç¿’ç²¾åº¦ã®æ¨ç§»')
    plt.legend()
    plt.grid(alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('biokan_mnist_training_history.png')
    print("å­¦ç¿’å±¥æ­´ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: biokan_mnist_training_history.png")

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if __name__ == "__main__":
    try:
        # MNISTãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰
        train_loader, test_loader = load_mnist_data(batch_size=128)
        
        # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        model = initialize_model()
        model = model.to(device)
        print(f"ãƒ¢ãƒ‡ãƒ«ã‚’{device}ã«è»¢é€ã—ã¾ã—ãŸ")
        
        # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
        trained_model, history = train_model(
            model, 
            train_loader, 
            test_loader,
            epochs=15,
            lr=0.001,
            weight_decay=1e-5
        )
        
        # å­¦ç¿’å±¥æ­´ã®å¯è¦–åŒ–
        plot_training_history(history)
        
        # æœ€çµ‚è©•ä¾¡
        _, final_acc = evaluate_model(trained_model, test_loader)
        print(f"\næœ€çµ‚ãƒ†ã‚¹ãƒˆç²¾åº¦: {final_acc:.4f}")
        
        print("\nå­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ä»¥ä¸‹ã®ãƒ‘ã‚¹ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™:")
        print("- æœ€é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«: best_biokan_mnist_model.pth")
        print("- æœ€çµ‚ãƒ¢ãƒ‡ãƒ«: final_biokan_mnist_model.pth")
        
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        # GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã®è¡¨ç¤º
        if torch.cuda.is_available():
            print("\nGPUãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³:")
            print(f"å‰²ã‚Šå½“ã¦æ¸ˆã¿ãƒ¡ãƒ¢ãƒª: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")
            print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒª: {torch.cuda.memory_reserved() / 1024**2:.1f} MB")
            # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±ã‚’å‡ºåŠ›
            import traceback
            traceback.print_exc()
            torch.cuda.empty_cache()  # GPUãƒ¡ãƒ¢ãƒªã®è§£æ”¾
    
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if torch.cuda.is_available():
            torch.cuda.empty_cache() 